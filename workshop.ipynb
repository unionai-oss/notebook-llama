{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop: üìñü¶ô NotebookLM Clone based on Llama Open Weights Models\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/unionai-oss/notebook-llama/blob/main/workshop.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "In this workshop, we'll be building a podcast generator from a PDF file.\n",
    "\n",
    "- üå† Workshop slides: https://go.union.ai/workshop-notebook-lm-clone\n",
    "- üì± Example app: https://shy-sun-51a14.apps.serverless-1.us-east-2.s.union.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß± Setup\n",
    "\n",
    "Before running this notebook, make sure you follow the prerequisites in the\n",
    "[README](https://github.com/unionai-oss/notebook-llama/blob/main/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !git clone https://github.com/unionai-oss/notebook-llama\n",
    "    %cd notebook-llama\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate this notebook session with Union:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union create login --auth device-flow --serverless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a Huggingface API key secret: https://huggingface.co/settings/tokens.\n",
    "\n",
    "Run the cell below to create the secret on Union. You'll be prompted to paste\n",
    "the string into the input field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union create secret huggingface_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't already, request access to the [Llama 3.2 3B model](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)\n",
    "and [Llama 3.2 1B model](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure the secret is created, run the cell below:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union get secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, register the `notebook_llama` tasks and workflows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union register notebook_llama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Setup a `UnionRemote` object\n",
    "\n",
    "First, let's create a `UnionRemote` object, which will allow us to interact with\n",
    "the Union platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import union\n",
    "import rich\n",
    "\n",
    "remote = union.UnionRemote(\n",
    "    default_project=\"default\",\n",
    "    default_domain=\"development\",\n",
    "    interactive_mode_enabled=False,\n",
    ")\n",
    "\n",
    "def print_prompt(title: str, prompt: str):\n",
    "    return rich.panel.Panel(prompt, title=title, width=120, border_style=\"red\")\n",
    "\n",
    "def print_text(title: str, text: str):\n",
    "    return rich.panel.Panel(text, title=title, width=120, border_style=\"yellow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÑ Extract Text from PDF\n",
    "\n",
    "The first step in our application is to extract text from the PDF file. We\n",
    "expect the output of this step to be in a raw text format, with all of the\n",
    "formatting artifacts of the PDF file removed.\n",
    "\n",
    "In this step we'll use a small language model to perform the extraction and\n",
    "clearning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_llama.preprocess_pdf import pdf_to_text, SYS_PROMPT as EXTRACT_PDF_SYS_PROMPT\n",
    "\n",
    "rich.print(print_prompt(\"PDF Extraction System Prompt\", EXTRACT_PDF_SYS_PROMPT))\n",
    "\n",
    "pdf_to_text_execution = remote.execute(\n",
    "    pdf_to_text,\n",
    "    inputs={\"pdf_path\": \"https://arxiv.org/pdf/2503.14233\"},\n",
    ")\n",
    "pdf_to_text_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the extracted text in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_to_text_execution = remote.wait(pdf_to_text_execution)\n",
    "extracted_text = pdf_to_text_execution.outputs[\"o0\"]\n",
    "\n",
    "with open(extracted_text) as f:\n",
    "    text = f.read()\n",
    "\n",
    "print_text(\"Extracted Text\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Write Transcript\n",
    "\n",
    "Next, we'll use a larger language model to write a draft of the transcript. This\n",
    "should output a file containing the contents of the transcript draft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_llama.write_transcript import write_transcript, SYSTEM_PROMPT as WRITE_TRANSCRIPT_SYSTEM_PROMPT\n",
    "\n",
    "rich.print(print_prompt(\"Write Transcript System Prompt\", WRITE_TRANSCRIPT_SYSTEM_PROMPT))\n",
    "\n",
    "write_transcript_execution = remote.execute(\n",
    "    write_transcript,\n",
    "    inputs={\"pdf_text\": extracted_text},\n",
    "    version=\"latest\",\n",
    ")\n",
    "\n",
    "write_transcript_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the execution is complete, we can take a look at the contents of the\n",
    "transcript draft below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_transcript_execution = remote.wait(write_transcript_execution)\n",
    "raw_transcript_file = write_transcript_execution.outputs[\"o0\"]\n",
    "\n",
    "with open(raw_transcript_file) as f:\n",
    "    raw_transcript = f.read()\n",
    "\n",
    "print_text(\"Raw Transcript\", raw_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úçÔ∏è Rewrite Transcript\n",
    "\n",
    "Next, we'll use the same language model to rewrite the transcript to punch up\n",
    "the script a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_llama.rewrite_transcript import rewrite_transcript, SYSTEM_PROMPT as REWRITE_TRANSCRIPT_SYSTEM_PROMPT\n",
    "\n",
    "rich.print(print_prompt(\"Rewrite Transcript System Prompt\", REWRITE_TRANSCRIPT_SYSTEM_PROMPT))\n",
    "\n",
    "rewrite_transcript_execution = remote.execute(\n",
    "    rewrite_transcript,\n",
    "    inputs={\"transcript\": raw_transcript_file},\n",
    "    version=\"latest\",\n",
    ")\n",
    "\n",
    "rewrite_transcript_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the rewritten transcript below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import rich.markdown\n",
    "\n",
    "rewrite_transcript_execution = remote.wait(rewrite_transcript_execution)\n",
    "rewritten_transcript_file = rewrite_transcript_execution.outputs[\"o0\"]\n",
    "\n",
    "with open(rewritten_transcript_file) as f:\n",
    "    rewritten_transcript = json.load(f)\n",
    "\n",
    "text = \"\"\n",
    "for speaker, line in rewritten_transcript:\n",
    "    text += f\"**{speaker}**: {line}\\n\\n\"\n",
    "\n",
    "print_text(\"Rewritten Transcript\", rich.markdown.Markdown(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Podcast\n",
    "\n",
    "Finally, we'll use a text-to-speech model to generate the podcast audio of\n",
    "our two speakers using the rewritten transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_llama.generate_podcast import generate_podcast, speaker1_description, speaker2_description\n",
    "\n",
    "rich.print(print_prompt(\"Speaker 1 Description\", speaker1_description))\n",
    "rich.print(print_prompt(\"Speaker 2 Description\", speaker2_description))\n",
    "\n",
    "generate_podcast_execution = remote.execute(\n",
    "    generate_podcast,\n",
    "    inputs={\"clean_transcript\": rewritten_transcript_file},\n",
    "    version=\"latest\",\n",
    ")\n",
    "\n",
    "generate_podcast_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "generate_podcast_execution = remote.wait(generate_podcast_execution)\n",
    "podcast_file = generate_podcast_execution.outputs[\"o0\"]\n",
    "\n",
    "podcast_file.download()\n",
    "Audio(podcast_file.path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Serving an application\n",
    "\n",
    "In the final part of this workshop, we'll serve the application to the public.\n",
    "This will run the entire workflow we just ran in a single click through a nice\n",
    "UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we need to create a Union API key called `notebook-llama-workshop` for app serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to store this key somewhere secure.\n",
    "!union create api-key admin --name notebook-llama-workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can list the api keys you have with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union get api-key admin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create an Union API key secret that we'll use for this workshop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!union create secret union_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app import app\n",
    "\n",
    "remote.deploy_app(app);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚≠êÔ∏è Conclusion\n",
    "\n",
    "Congrats! You've just deployed your first Compound AI System. We used multiple\n",
    "models of different sizes and modalities to create a pipeline that generates\n",
    "podcast audio from a PDF file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
